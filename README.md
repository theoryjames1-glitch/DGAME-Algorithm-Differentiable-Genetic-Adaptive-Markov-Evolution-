Alright â€” hereâ€™s a **formal pseudocode** for the **Differentiable Genetic Adaptive Markov Evolution (DGAME)** algorithm, written in the same clean style as *Clever Algorithms*.

---

# ğŸ”¹ DGAME Algorithm (Differentiable Genetic Adaptive Markov Evolution)

---

## **Procedure**

```
procedure DGAME(f, Î¸0, C0, T, probe_eps, k_net, s_net)
    Input:
        f        : objective function (loss)
        Î¸0       : initial parameter vector
        C0       : initial coefficient vector
        T        : number of iterations
        probe_eps: probe step size for SPSA estimate
        k_net    : controller net for drift gain K
        s_net    : controller net for mutation scale Î£

    Output:
        Î¸T       : evolved parameter vector
```

---

## **Main Loop**

```
Î¸ â† Î¸0
C â† C0

for t = 0 â€¦ T-1 do
    # 1. Evaluate current loss
    L_t â† f(Î¸)

    # 2. SPSA probe for stochastic gradient estimate
    Î´   â† random_vector(dim(Î¸))
    Lp  â† f(Î¸ + probe_eps * Î´)
    Lm  â† f(Î¸ - probe_eps * Î´)
    Ä   â† ((Lp - Lm) / (2 * probe_eps)) * Î´
    Ä   â† Ä / (||Ä|| + Îµ)

    # 3. Controller nets produce adaptive gains
    K   â† clamp( softplus( k_net(C) ), max = k_max )
    Î£   â† clamp( softplus( s_net(C) ), max = sig_max )

    # 4. Evolution update (AME law)
    Î¾   â† random_vector(dim(Î¸))
    D   â† dither_signal()
    Î¸   â† Î¸ - K * Ä + Î£ * Î¾ + D
    Î¸   â† clamp(Î¸, -Î¸_clip, Î¸_clip)

    # 5. Feedback update of coefficients
    L_next â† f(Î¸)
    Î”L     â† L_next - L_t
    V      â† mean(Ä^2)
    C      â† C - Î±1 * sign(Î”L) * C + Î±2 * (target_V - V) + Î±3 * noise()

    # 6. Train controller nets with surrogate signal
    surrogate â† L_next * (K + Î£)
    backprop(surrogate, k_net, s_net)

end for

return Î¸
```

---

## **Key Points**

* **Parameters Î¸** = the evolving population (each weight = gene).
* **Coefficients C** = adaptive control states for each weight.
* **Evolution law (AME)** = Markov drift + mutation + dither.
* **Differentiable controllers** $k\_net, s\_net$ adapt mutation/drift online.
* **SPSA probe** provides gradient-free direction estimate.

---

# ğŸ”¹ Intuition

* Each parameter **is an individual**.
* The population evolves by AME dynamics.
* Controller nets make the whole process **differentiable and learnable**.
* This unifies **genetic search + adaptive Markov processes**.

---

âœ… This is a **ready-to-publish pseudocode description** of DGAME.

Do you want me to now also provide a **diagram** (boxes + arrows) showing how forward pass, loss, SPSA probe, AME update, and controller nets all connect in the DGAME loop?
